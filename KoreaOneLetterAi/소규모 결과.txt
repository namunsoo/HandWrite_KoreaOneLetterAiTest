Found 729248 files belonging to 11172 classes.
Using 583399 files for training.
Using 145849 files for validation.
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 rescaling (Rescaling)       (None, 56, 56, 1)         0

 conv2d (Conv2D)             (None, 54, 54, 16)        160

 max_pooling2d (MaxPooling2  (None, 27, 27, 16)        0
 D)

 conv2d_1 (Conv2D)           (None, 25, 25, 32)        4640

 max_pooling2d_1 (MaxPoolin  (None, 12, 12, 32)        0
 g2D)

 conv2d_2 (Conv2D)           (None, 10, 10, 64)        18496

 max_pooling2d_2 (MaxPoolin  (None, 5, 5, 64)          0
 g2D)

 dropout (Dropout)           (None, 5, 5, 64)          0

 flatten (Flatten)           (None, 1600)              0

 dense (Dense)               (None, 11172)             17886372

=================================================================
Total params: 17909668 (68.32 MB)
Trainable params: 17909668 (68.32 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
Epoch 1/15
570/570 [==============================] - 1357s 2s/step - loss: 7.4588 - sparse_categorical_accuracy: 0.0326 - val_loss: 5.2428 - val_sparse_categorical_accuracy: 0.1094
Epoch 2/15
570/570 [==============================] - 1051s 2s/step - loss: 4.3894 - sparse_categorical_accuracy: 0.1845 - val_loss: 4.2372 - val_sparse_categorical_accuracy: 0.1964
Epoch 3/15
570/570 [==============================] - 1110s 2s/step - loss: 3.5089 - sparse_categorical_accuracy: 0.2851 - val_loss: 3.8387 - val_sparse_categorical_accuracy: 0.2436
Epoch 4/15
570/570 [==============================] - 1072s 2s/step - loss: 3.0002 - sparse_categorical_accuracy: 0.3567 - val_loss: 3.6014 - val_sparse_categorical_accuracy: 0.2753
Epoch 5/15
570/570 [==============================] - 1099s 2s/step - loss: 2.6498 - sparse_categorical_accuracy: 0.4091 - val_loss: 3.4793 - val_sparse_categorical_accuracy: 0.2948
Epoch 6/15
570/570 [==============================] - 1105s 2s/step - loss: 2.3872 - sparse_categorical_accuracy: 0.4514 - val_loss: 3.3946 - val_sparse_categorical_accuracy: 0.3096
Epoch 7/15
570/570 [==============================] - 1094s 2s/step - loss: 2.1833 - sparse_categorical_accuracy: 0.4853 - val_loss: 3.3412 - val_sparse_categorical_accuracy: 0.3236
Epoch 8/15
570/570 [==============================] - 1087s 2s/step - loss: 2.0224 - sparse_categorical_accuracy: 0.5124 - val_loss: 3.3214 - val_sparse_categorical_accuracy: 0.3310
Epoch 9/15
570/570 [==============================] - 1117s 2s/step - loss: 1.8944 - sparse_categorical_accuracy: 0.5331 - val_loss: 3.3240 - val_sparse_categorical_accuracy: 0.3384
Epoch 10/15
570/570 [==============================] - 1145s 2s/step - loss: 1.7817 - sparse_categorical_accuracy: 0.5535 - val_loss: 3.3014 - val_sparse_categorical_accuracy: 0.3443
Epoch 11/15
570/570 [==============================] - 1107s 2s/step - loss: 1.6886 - sparse_categorical_accuracy: 0.5701 - val_loss: 3.3119 - val_sparse_categorical_accuracy: 0.3483
Epoch 12/15
570/570 [==============================] - 1098s 2s/step - loss: 1.6099 - sparse_categorical_accuracy: 0.5845 - val_loss: 3.3133 - val_sparse_categorical_accuracy: 0.3515
Epoch 13/15
570/570 [==============================] - 1098s 2s/step - loss: 1.5401 - sparse_categorical_accuracy: 0.5977 - val_loss: 3.3051 - val_sparse_categorical_accuracy: 0.3562