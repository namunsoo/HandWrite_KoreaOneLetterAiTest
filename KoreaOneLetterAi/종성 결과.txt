Found 729249 files belonging to 28 classes.
Using 583400 files for training.
Using 145849 files for validation.
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 rescaling (Rescaling)       (None, 56, 56, 1)         0

 conv2d (Conv2D)             (None, 54, 54, 32)        320

 max_pooling2d (MaxPooling2  (None, 27, 27, 32)        0
 D)

 conv2d_1 (Conv2D)           (None, 25, 25, 64)        18496

 max_pooling2d_1 (MaxPoolin  (None, 12, 12, 64)        0
 g2D)

 conv2d_2 (Conv2D)           (None, 10, 10, 128)       73856

 max_pooling2d_2 (MaxPoolin  (None, 5, 5, 128)         0
 g2D)

 dropout (Dropout)           (None, 5, 5, 128)         0

 flatten (Flatten)           (None, 3200)              0

 dense (Dense)               (None, 28)                89628

=================================================================
Total params: 182300 (712.11 KB)
Trainable params: 182300 (712.11 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python39_64\lib\site-packages\keras\src\backend.py:5729: UserWarning: "`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?
  output, from_logits = _get_logits(
570/570 [==============================] - 2546s 4s/step - loss: 1.2809 - sparse_categorical_accuracy: 0.6294 - val_loss: 0.5324 - val_sparse_categorical_accuracy: 0.8500
570/570 [==============================] - 2552s 4s/step - loss: 0.4760 - sparse_categorical_accuracy: 0.8618 - val_loss: 0.3358 - val_sparse_categorical_accuracy: 0.9054
570/570 [==============================] - 2557s 4s/step - loss: 0.3485 - sparse_categorical_accuracy: 0.8991 - val_loss: 0.2701 - val_sparse_categorical_accuracy: 0.9235
570/570 [==============================] - 2549s 4s/step - loss: 0.2878 - sparse_categorical_accuracy: 0.9162 - val_loss: 0.2272 - val_sparse_categorical_accuracy: 0.9355
570/570 [==============================] - 2543s 4s/step - loss: 0.2514 - sparse_categorical_accuracy: 0.9268 - val_loss: 0.2096 - val_sparse_categorical_accuracy: 0.9409
570/570 [==============================] - 2570s 4s/step - loss: 0.2267 - sparse_categorical_accuracy: 0.9340 - val_loss: 0.1861 - val_sparse_categorical_accuracy: 0.9472
570/570 [==============================] - 2554s 4s/step - loss: 0.2075 - sparse_categorical_accuracy: 0.9395 - val_loss: 0.1772 - val_sparse_categorical_accuracy: 0.9503
570/570 [==============================] - 2550s 4s/step - loss: 0.1942 - sparse_categorical_accuracy: 0.9433 - val_loss: 0.1751 - val_sparse_categorical_accuracy: 0.9498
570/570 [==============================] - 2543s 4s/step - loss: 0.1823 - sparse_categorical_accuracy: 0.9464 - val_loss: 0.1623 - val_sparse_categorical_accuracy: 0.9543
570/570 [==============================] - 2549s 4s/step - loss: 0.1739 - sparse_categorical_accuracy: 0.9489 - val_loss: 0.1561 - val_sparse_categorical_accuracy: 0.9560
570/570 [==============================] - 2550s 4s/step - loss: 0.1659 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1523 - val_sparse_categorical_accuracy: 0.9570
570/570 [==============================] - 2511s 4s/step - loss: 0.1595 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.1504 - val_sparse_categorical_accuracy: 0.9579
570/570 [==============================] - 2548s 4s/step - loss: 0.1537 - sparse_categorical_accuracy: 0.9550 - val_loss: 0.1453 - val_sparse_categorical_accuracy: 0.9597
570/570 [==============================] - 2548s 4s/step - loss: 0.1469 - sparse_categorical_accuracy: 0.9570 - val_loss: 0.1464 - val_sparse_categorical_accuracy: 0.9591
570/570 [==============================] - 2559s 4s/step - loss: 0.1432 - sparse_categorical_accuracy: 0.9576 - val_loss: 0.1425 - val_sparse_categorical_accuracy: 0.9601